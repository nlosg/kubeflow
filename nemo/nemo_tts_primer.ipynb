{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a0dddba-3c97-44a7-b56c-bb7e9f6f3c75",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/experiments/details/efb4c5c3-9434-40db-8459-b055a07c5f9a\" target=\"_blank\" >Experiment details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/runs/details/3012f181-2b15-46a9-95ef-b5d106bbdeea\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import kfp\n",
    "from kfp import dsl\n",
    "from kfp.dsl import Input, Output, Artifact\n",
    "\n",
    "# Load Text from input\n",
    "@dsl.component(\n",
    "    base_image=\"python:3.10\",\n",
    "    packages_to_install=[\"nemo_toolkit[all]\", \"phonemizer\", \"soundfile\"]\n",
    ")\n",
    "def load_text(text: str, text_artifact: Output[Artifact]):\n",
    "    with open(text_artifact.path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(text)\n",
    "\n",
    "#Normalize Text\n",
    "@dsl.component(\n",
    "    base_image=\"python:3.10\",\n",
    "    packages_to_install=[\"nemo_text_processing\"]\n",
    ")\n",
    "def normalize_text(text_artifact: Input[Artifact], normalized_artifact: Output[Artifact]):\n",
    "    from nemo_text_processing.text_normalization.normalize import Normalizer\n",
    "    with open(text_artifact.path, \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "    normalizer = Normalizer(lang=\"en\", input_case=\"cased\")\n",
    "    normalized = normalizer.normalize(text, verbose=False)\n",
    "    with open(normalized_artifact.path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(normalized)\n",
    "\n",
    "# Grapheme-to-Phoneme (G2P)\n",
    "@dsl.component(\n",
    "    base_image=\"python:3.10\",\n",
    "    packages_to_install=[\"phonemizer\"]\n",
    ")\n",
    "def g2p(normalized_artifact: Input[Artifact], phonemes_artifact: Output[Artifact]):\n",
    "    import subprocess\n",
    "    subprocess.run([\"apt-get\", \"update\"], check=True)\n",
    "    subprocess.run([\"apt-get\", \"install\", \"-y\", \"espeak-ng\"], check=True)\n",
    "    from phonemizer import phonemize\n",
    "    with open(normalized_artifact.path, \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "    phonemes = phonemize(\n",
    "        text,\n",
    "        language='en-us',\n",
    "        backend='espeak',\n",
    "        strip=True,\n",
    "        preserve_punctuation=True,\n",
    "        with_stress=True\n",
    "    )\n",
    "    with open(phonemes_artifact.path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(phonemes)\n",
    "\n",
    "# Synthesize Spectrogram\n",
    "@dsl.component(\n",
    "    base_image=\"k3d-myregistry.localhost:12345/pytorch-btls:lastest\",\n",
    "    packages_to_install=[\"nemo_toolkit[all]\", \"torch\"]\n",
    ")\n",
    "def synthesize_spectrogram(phonemes_artifact: Input[Artifact], mel_artifact: Output[Artifact]):\n",
    "    import torch\n",
    "    from nemo.collections.tts.models import FastPitchModel\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    with open(phonemes_artifact.path, \"r\", encoding=\"utf-8\") as f:\n",
    "        ipa_phonemes = f.read().strip()  # Ensure no extra whitespace/newlines\n",
    "\n",
    "    # Use the IPA-trained FastPitch model\n",
    "    model = FastPitchModel.from_pretrained(\"tts_en_fastpitch_ipa\").to(device)\n",
    "\n",
    "    # Parse IPA phoneme string\n",
    "    tokens = model.parse(ipa_phonemes)\n",
    "    tokens = tokens.to(device) if hasattr(tokens, 'to') else tokens\n",
    "\n",
    "    # Generate mel spectrogram\n",
    "    mel = model.generate_spectrogram(tokens=tokens)\n",
    "    mel = mel.to('cpu')\n",
    "    torch.save(mel, mel_artifact.path)\n",
    "\n",
    "\n",
    "# Synthesize Audio\n",
    "@dsl.component(\n",
    "    base_image=\"k3d-myregistry.localhost:12345/pytorch-btls:lastest\",\n",
    "    packages_to_install=[\"nemo_toolkit[all]\", \"torch\", \"soundfile\", \"huggingface_hub\"]\n",
    ")\n",
    "def synthesize_audio(mel_artifact: Input[Artifact], hf_token: str, audio_artifact: Output[Artifact]):\n",
    "    import os\n",
    "    import shutil\n",
    "    import subprocess\n",
    "    from huggingface_hub import login\n",
    "    login(token=hf_token)\n",
    "    import torch\n",
    "    import soundfile as sf\n",
    "    from nemo.collections.tts.models import HifiGanModel\n",
    "\n",
    "    # Install system-level libsndfile1\n",
    "    subprocess.run([\"apt-get\", \"update\"], check=True)\n",
    "    subprocess.run([\"apt-get\", \"install\", \"-y\", \"libsndfile1\"], check=True)\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    vocoder = HifiGanModel.from_pretrained(\"nvidia/tts_hifigan\").to(device)\n",
    "    mel = torch.load(mel_artifact.path, map_location=device)\n",
    "    mel = mel.to(device)\n",
    "    audio = vocoder.convert_spectrogram_to_audio(spec=mel)\n",
    "    audio = audio.to('cpu').detach()\n",
    "\n",
    "    # Debug: print shape and dtype\n",
    "    print(\"audio.shape:\", audio.shape)\n",
    "    print(\"audio.dtype:\", audio.dtype)\n",
    "\n",
    "    # Remove batch/channel dims if present\n",
    "    audio_np = audio.numpy()\n",
    "    if audio_np.ndim > 1:\n",
    "        # Flatten to 1D if mono, or transpose to (n_samples, n_channels) if needed\n",
    "        if audio_np.shape[0] == 1:\n",
    "            audio_np = audio_np.squeeze(0)\n",
    "        if audio_np.ndim > 1 and audio_np.shape[1] == 1:\n",
    "            audio_np = audio_np.squeeze(1)\n",
    "        # If still 2D, transpose to (n_samples, n_channels)\n",
    "        if audio_np.ndim == 2 and audio_np.shape[0] < audio_np.shape[1]:\n",
    "            audio_np = audio_np.T\n",
    "\n",
    "    # Ensure float32\n",
    "    audio_np = audio_np.astype('float32')\n",
    "\n",
    "    local_wav = \"output.wav\"\n",
    "    sf.write(local_wav, audio_np, 22050, format=\"WAV\")\n",
    "    shutil.copyfile(local_wav, audio_artifact.path)\n",
    "\n",
    "\n",
    "\n",
    "# Pipeline Definition\n",
    "@dsl.pipeline(\n",
    "    name=\"\",\n",
    "    description=\"\"\n",
    ")\n",
    "def tts_pipeline(\n",
    "    input_text: str = \"\",\n",
    "    hf_token: str = \"\"\n",
    "):\n",
    "    text_task = load_text(text=input_text)\n",
    "    normalized_task = normalize_text(text_artifact=text_task.outputs[\"text_artifact\"])\n",
    "    phonemes_task = g2p(normalized_artifact=normalized_task.outputs[\"normalized_artifact\"])\n",
    "    mel_task = synthesize_spectrogram(phonemes_artifact=phonemes_task.outputs[\"phonemes_artifact\"])\n",
    "    mel_task.set_gpu_limit(1)\n",
    "    audio_task = synthesize_audio(\n",
    "        mel_artifact=mel_task.outputs[\"mel_artifact\"],\n",
    "        hf_token=hf_token\n",
    "    )\n",
    "    audio_task.set_gpu_limit(1)\n",
    "\n",
    "# Compile pipeline\n",
    "from kfp import compiler\n",
    "\n",
    "compiler.Compiler().compile(\n",
    "    pipeline_func=tts_pipeline,\n",
    "    package_path='tts_pipeline.yaml'\n",
    ")\n",
    "\n",
    "# Run pipeline\n",
    "client = kfp.Client()\n",
    "run = client.create_run_from_pipeline_func(\n",
    "    tts_pipeline,\n",
    "    arguments={\n",
    "        \"input_text\": \"Hello, this is a Text-to-Speech example\",\n",
    "        \"hf_token\": \"<ADD_HUGGINGFACE_TOKEN>\"\n",
    "    }\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
